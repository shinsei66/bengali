{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../input/train.csv\n",
      "../../input/test.csv\n",
      "../../input/class_map.csv\n",
      "../../input/.gitkeep\n",
      "../../input/sample_submission.csv\n",
      "../../input/parquet/train_image_data_2.parquet\n",
      "../../input/parquet/test_image_data_2.parquet\n",
      "../../input/parquet/train_image_data_3.parquet\n",
      "../../input/parquet/test_image_data_1.parquet\n",
      "../../input/parquet/test_image_data_0.parquet\n",
      "../../input/parquet/test_image_data_3.parquet\n",
      "../../input/parquet/train_image_data_0.parquet\n",
      "../../input/parquet/train_image_data_1.parquet\n",
      "../../input/feather/train_image_data_2.feather\n",
      "../../input/feather/test_image_data_1.feather\n",
      "../../input/feather/train_image_data_1.feather\n",
      "../../input/feather/test_image_data_3.feather\n",
      "../../input/feather/train_image_data_0.feather\n",
      "../../input/feather/test_image_data_0.feather\n",
      "../../input/feather/test_image_data_2.feather\n",
      "../../input/feather/train_image_data_3.feather\n"
     ]
    }
   ],
   "source": [
    "#+---- Basic Libraries ----+#\n",
    "import sys, os, time, gc, random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "from utils import *\n",
    "\n",
    "#+---- Utilities Libraries ----+#\n",
    "#import albumentations as albu\n",
    "import pretrainedmodels\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#+---- Pytorch Libraries ----+#\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils import model_zoo\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import functional as F\n",
    "\n",
    "#+---- List the input data ----+#\n",
    "for dirname, _, filenames in os.walk('../../input/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Initial Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = Path('../../input')\n",
    "FEATHERDIR = Path('../../input/feather')\n",
    "OUTDIR = Path('../../output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input', '.gitignore', 'README.md', '.git', 'src', 'submission', 'output']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG =False\n",
    "SUBMISSION =False\n",
    "BATCH_SIZE =32\n",
    "NUM_EPOCH = 36\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "MDL_DIR = '../models'\n",
    "LOG_DIR = '../logs'\n",
    "IMAGE_SIZE=224\n",
    "TRAIN_RATIO = 0.9\n",
    "WORKER = 4\n",
    "SEED = 6666\n",
    "MODEL_NAME ='efficientnet-b4'\n",
    "N_Fold = 10\n",
    "CV = True\n",
    "Fold = 2\n",
    "PATIAENCE = 4\n",
    "VER = 'fold_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grapheme = 168\n",
    "n_vowel = 11\n",
    "n_consonant = 7\n",
    "n_total = n_grapheme + n_vowel + n_consonant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform class for data preprocessing and augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(datadir, featherdir, data_type='train',\n",
    "                  submission=False, indices=[0, 1, 2, 3]):\n",
    "    assert data_type in ['train', 'test']\n",
    "    if submission:\n",
    "        image_df_list = [pd.read_parquet(datadir / f'{data_type}_image_data_{i}.parquet')\n",
    "                         for i in indices]\n",
    "    else:\n",
    "        image_df_list = [pd.read_feather(featherdir / f'{data_type}_image_data_{i}.feather')\n",
    "                         for i in indices]\n",
    "\n",
    "    print('image_df_list', len(image_df_list))\n",
    "    HEIGHT = 137\n",
    "    WIDTH = 236\n",
    "    images = [df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH) for df in image_df_list]\n",
    "    del image_df_list\n",
    "    gc.collect()\n",
    "    images = np.concatenate(images, axis=0)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_char_image(image, threshold=5./255.):\n",
    "    assert image.ndim == 2\n",
    "    is_black = image > threshold\n",
    "\n",
    "    is_black_vertical = np.sum(is_black, axis=0) > 0\n",
    "    is_black_horizontal = np.sum(is_black, axis=1) > 0\n",
    "    left = np.argmax(is_black_horizontal)\n",
    "    right = np.argmax(is_black_horizontal[::-1])\n",
    "    top = np.argmax(is_black_vertical)\n",
    "    bottom = np.argmax(is_black_vertical[::-1])\n",
    "    height, width = image.shape\n",
    "    cropped_image = image[left:height - right, top:width - bottom]\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        #transforms.ToPILImage(),\n",
    "        transforms.ColorJitter(0.5,0.5,0.5,0.5),\n",
    "        transforms.RandomAffine(degrees=0.6),\n",
    "        transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    \n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        #transforms.ToPILImage(),\n",
    "        transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        #transforms.ToPILImage(),\n",
    "        transforms.Resize((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BengaliAIDataset(Dataset):\n",
    "    def __init__(self, images, labels=None, transform=None, indices=None):\n",
    "        self.transform = transform\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        if indices is None:\n",
    "            indices = np.arange(len(images))\n",
    "        self.indices = indices\n",
    "        self.train = labels is not None\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return length of this dataset\"\"\"\n",
    "        return len(self.indices)\n",
    "      \n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"Return i-th data\"\"\"\n",
    "        i = self.indices[i]\n",
    "        x = self.images[i]\n",
    "        # Opposite white and black: background will be white and\n",
    "        # for future Affine transformation\n",
    "        x = (255 - x).astype(np.float32) #/ 255.\n",
    "        x = crop_char_image(x)\n",
    "        x = Image.fromarray(x).convert(\"RGB\")\n",
    "        x = self.transform(x)\n",
    "        if self.train:\n",
    "            y = self.labels[i]\n",
    "            return x, y\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n",
      "Fold 5\n",
      "Fold 6\n",
      "Fold 7\n",
      "Fold 8\n",
      "Fold 9\n",
      "Fold 10\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(DATADIR/'train.csv')\n",
    "train['id'] = train['image_id'].apply(lambda x: int(x.split('_')[1]))\n",
    "X, y = train[['id', 'grapheme_root', 'vowel_diacritic', 'consonant_diacritic']]\\\n",
    ".values[:,0], train.values[:,1:]\n",
    "train['fold'] = np.nan\n",
    "mskf = MultilabelStratifiedKFold(n_splits=N_Fold)\n",
    "for i, (_, index) in enumerate(mskf.split(X, y)):\n",
    "    print('Fold '+str(i+1))\n",
    "    train.iloc[index, -1] = i\n",
    "train['fold'] = train['fold'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#train = pd.read_csv(DATADIR/'train.csv')\n",
    "train_labels = train[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "indices = [0] if DEBUG else [0, 1, 2, 3]\n",
    "train_images = prepare_image(\n",
    "    DATADIR, FEATHERDIR, data_type='train', submission=False, indices=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dataset = len(train_images)\n",
    "\n",
    "if not CV:\n",
    "    train_data_size = 200 if DEBUG else int(n_dataset * TRAIN_RATIO)\n",
    "    valid_data_size = 100 if DEBUG else int(n_dataset - train_data_size)\n",
    "    perm = np.random.RandomState(777).permutation(n_dataset)\n",
    "    print('perm', perm)\n",
    "\n",
    "    train_dataset = BengaliAIDataset(\n",
    "        train_images, train_labels, transform=data_transforms['train'],\n",
    "        indices=perm[:train_data_size])\n",
    "\n",
    "    valid_dataset = BengaliAIDataset(\n",
    "        train_images, train_labels, transform=data_transforms['val'],\n",
    "        indices=perm[train_data_size:train_data_size+valid_data_size])\n",
    "else:\n",
    "    valid_idx = np.array(train[train['fold']==Fold].index)\n",
    "    trn_idx = np.array(train[train['fold']!=Fold].index)\n",
    "    trn_idx = trn_idx[:200] if DEBUG else trn_idx\n",
    "    valid_idx = valid_idx[:100] if DEBUG else valid_idx\n",
    "    \n",
    "    train_dataset = BengaliAIDataset(\n",
    "        train_images, train_labels, transform=data_transforms['train'],\n",
    "        indices=trn_idx)\n",
    "    valid_dataset = BengaliAIDataset(\n",
    "        train_images, train_labels, transform=data_transforms['val'],\n",
    "        indices=valid_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=WORKER)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKER)\n",
    "\n",
    "dataloaders = {'train':train_loader, 'val': valid_loader}\n",
    "dataset_sizes = {'train':len(train_dataset), 'val': len(valid_dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2, ..., 200837, 200838, 200839])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image torch.Size([3, 224, 224]) label [159   0   0]\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[1]\n",
    "print('image', image.shape, 'label', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model/Train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler,start_epoch, num_epochs, device, patiance):\n",
    "    since = time.time()\n",
    "    \n",
    "    trn_loss_list =[]\n",
    "    trn_acc_list = []\n",
    "    val_loss_list =[]\n",
    "    val_acc_list = []\n",
    "    epoch_list = []\n",
    "    \n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(num_epochs)[start_epoch:]:\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        if early_stopping_counter == patiance:\n",
    "            print(f'Early Stopped since loss have not decreased for {patiance} epoch.')\n",
    "            break\n",
    "        epoch_list.append(epoch)\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            epoch_loss = 0.0\n",
    "            epoch_corrects = 0\n",
    "            dataset_sizes = len(dataloaders[phase].dataset)\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                #print(inputs.shape)\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.transpose(1,0).to(device) #use when single label for one image\n",
    "\n",
    "                grapheme_root = labels[0]\n",
    "                vowel_diacritic = labels[1]\n",
    "                consonant_diacritic = labels[2]\n",
    "\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs) \n",
    "                    #_, preds = torch.max(outputs, 1)\n",
    "                    #outputs shape is tuple with (bs, num_class1), (bs, num_class2), (bs, num_class3)\n",
    "                    grapheme_root_prd = outputs[0]\n",
    "                    vowel_diacritic_prd = outputs[1]\n",
    "                    consonant_diacritic_prd = outputs[2]\n",
    "\n",
    "\n",
    "                    #loss = criterion(outputs, labels)\n",
    "                    #output shape : (batch size, class number)\n",
    "                    #label shape : batch size\n",
    "                    loss = (1/3)*(criterion(grapheme_root_prd, grapheme_root)+\\\n",
    "                                criterion(vowel_diacritic_prd, vowel_diacritic) +\\\n",
    "                                  criterion(consonant_diacritic_prd, consonant_diacritic))\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics: inputs.size(0) is batch size\n",
    "                epoch_loss += loss.item() * inputs.size(0) # total loss for this batch\n",
    "                epoch_corrects += torch.sum(torch.max(outputs[0], 1)[1] == labels[0])+\\\n",
    "                    torch.sum(torch.max(outputs[1], 1)[1] == labels[1])+\\\n",
    "                    torch.sum(torch.max(outputs[2], 1)[1] == labels[2])\n",
    "            if phase == 'val':\n",
    "                #scheduler.step()\n",
    "                # if plateau scheduler use following\n",
    "                scheduler.step(epoch_loss)\n",
    "\n",
    "            epoch_loss = epoch_loss / dataset_sizes\n",
    "            epoch_acc = epoch_corrects.double() / (dataset_sizes*3)\n",
    "            \n",
    "            if phase == 'train':\n",
    "                trn_loss_list.append(epoch_loss)\n",
    "                trn_acc_list.append(epoch_acc.cpu().numpy())\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # Deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                if not os.path.exists(f'{MDL_DIR}/{MODEL_NAME}_{VER}'):\n",
    "                    os.mkdir(f'{MDL_DIR}/{MODEL_NAME}_{VER}')\n",
    "                save_path = f'{MDL_DIR}/{MODEL_NAME}_{VER}/{MODEL_NAME}_'+str(epoch)+'.pth'\n",
    "                torch.save(model_ft.state_dict(),save_path)\n",
    "                best_epoch = epoch\n",
    "            \n",
    "            if phase == 'val':\n",
    "                val_loss_list.append(epoch_loss)\n",
    "                val_acc_list.append(epoch_acc.cpu().numpy())\n",
    "                # Early Stopping\n",
    "                if epoch == 0 or epoch == start_epoch:\n",
    "                    best_loss = epoch_loss\n",
    "                else:\n",
    "                    if epoch_loss < best_loss:\n",
    "                        best_loss = epoch_loss\n",
    "                    else:\n",
    "                        early_stopping_counter += 1\n",
    "                        print(f'Early stopping counter: {early_stopping_counter}')\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    log = pd.DataFrame()\n",
    "    log['Epoch'] = epoch_list\n",
    "    log['Train Loss'] = trn_loss_list\n",
    "    log['Train Acc'] = trn_acc_list\n",
    "    log['Valid Loss'] = val_loss_list\n",
    "    log['Valid Acc'] = val_acc_list\n",
    "    log.to_csv(f'{LOG_DIR}/log_{MODEL_NAME}_{VER}.csv',index=False)\n",
    "        \n",
    "    return model, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bengali_model(nn.Module):\n",
    "    def __init__(self, num_classes1, num_classes2, num_classes3):\n",
    "        super(bengali_model, self).__init__()\n",
    "        #pretrain models\n",
    "        #self.model = pretrainedmodels.__dict__[MODEL_NAME](pretrained=None)\n",
    "        #num_ftrs = self.model.last_linear.in_features\n",
    "        #self.model.last_linear = nn.Identity()\n",
    "        \n",
    "        # EfficientNet\n",
    "        self.model = EfficientNet.from_pretrained(MODEL_NAME)\n",
    "        num_ftrs = 1792\n",
    "        \n",
    "        self.fc1 = nn.Linear(num_ftrs, num_classes1)\n",
    "        self.fc2 = nn.Linear(num_ftrs, num_classes2)\n",
    "        self.fc3 = nn.Linear(num_ftrs, num_classes3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = self.model(x) #pretrain models\n",
    "        bs, _, _, _ = x.shape\n",
    "        x = self.model.extract_features(x)\n",
    "        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n",
    "        out1 = self.fc1(x)\n",
    "        out2 = self.fc2(x)\n",
    "        out3 = self.fc3(x)\n",
    "        return out1, out2, out3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method EfficientNet.extract_features of EfficientNet(\n",
       "  (_conv_stem): Conv2dStaticSamePadding(\n",
       "    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
       "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "  )\n",
       "  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_blocks): ModuleList(\n",
       "    (0): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (1): MBConvBlock(\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (2): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (3): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (4): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (5): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (6): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (7): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (8): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (9): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (10): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (11): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (12): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (13): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (14): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (15): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (16): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (17): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (18): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (19): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (20): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (21): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (22): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (23): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (24): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (25): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (26): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (27): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (28): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (29): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (30): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "    (31): MBConvBlock(\n",
       "      (_expand_conv): Conv2dStaticSamePadding(\n",
       "        448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
       "        2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
       "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
       "      )\n",
       "      (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_se_reduce): Conv2dStaticSamePadding(\n",
       "        2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_se_expand): Conv2dStaticSamePadding(\n",
       "        112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_project_conv): Conv2dStaticSamePadding(\n",
       "        2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "        (static_padding): Identity()\n",
       "      )\n",
       "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "      (_swish): MemoryEfficientSwish()\n",
       "    )\n",
       "  )\n",
       "  (_conv_head): Conv2dStaticSamePadding(\n",
       "    448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
       "    (static_padding): Identity()\n",
       "  )\n",
       "  (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
       "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
       "  (_dropout): Dropout(p=0.4, inplace=False)\n",
       "  (_fc): Linear(in_features=1792, out_features=1000, bias=True)\n",
       "  (_swish): MemoryEfficientSwish()\n",
       ")>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EfficientNet.from_pretrained(MODEL_NAME).extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    }
   ],
   "source": [
    "# --- Model --- Stage 1\n",
    "\n",
    "model_ft = bengali_model(n_grapheme, n_vowel, n_consonant)\n",
    "model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.7, patience=5, min_lr=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfdec50275e4ae4abd7466107215d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.3160 Acc: 0.9103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d8cdd46a894e59b834ac451b3b02b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1834 Acc: 0.9481\n",
      "Epoch 2/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e53dc1e3a2243a3a47ba02d2b4b9b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.1498 Acc: 0.9568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87db4a0aa6714328b441f3a18d19a723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1405 Acc: 0.9619\n",
      "Epoch 3/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3b6a118a594bfcb4fa7925fbc81ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.1179 Acc: 0.9659\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0663e3bcca466daf4a21a6ba73e8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1240 Acc: 0.9661\n",
      "Epoch 4/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373e61587ad94d3eab4ad47cfae9e899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0975 Acc: 0.9719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9310bb73ec4cae9101535ef5058649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1205 Acc: 0.9680\n",
      "Epoch 5/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d11d74cef54547b8a2439b986637329c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0818 Acc: 0.9761\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339253e2ea734b84ba1e4a6c8342673f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1171 Acc: 0.9690\n",
      "Epoch 6/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e120e0864dad4170b7ba48d28f21ba12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0715 Acc: 0.9789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab89ffa7350d453394f72fb3a613b642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1119 Acc: 0.9702\n",
      "Epoch 7/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "408222487ec14b27af5a1cec243444b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0626 Acc: 0.9813\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3f35100d744467a24c29eb385fe1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1093 Acc: 0.9722\n",
      "Epoch 8/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fef4d7a7ccb4caab4c33e72cd15941a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0549 Acc: 0.9833\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e91a80b7b4742a2add92241eb13dc87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1019 Acc: 0.9752\n",
      "Epoch 9/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde10c81c0fa438c99e5a4c05bc8e5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0496 Acc: 0.9849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b62dedadb94f639ae28e6a799b9b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1084 Acc: 0.9728\n",
      "Early stopping counter: 1\n",
      "Epoch 10/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2eaffec83d40948158ee82389d947b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0436 Acc: 0.9867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3b961856aa48b3bf173bce04ee2fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1075 Acc: 0.9739\n",
      "Early stopping counter: 2\n",
      "Epoch 11/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1595e2cc9d45288d4aee27e3e2c633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0391 Acc: 0.9878\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7da02c55a7c4fd2a6a0a3e7e6884269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1126 Acc: 0.9739\n",
      "Early stopping counter: 3\n",
      "Epoch 12/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970f6c46f70e47439b319a634a42f161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0364 Acc: 0.9886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6049ab7dc71446a9a8ee4beb2ebd6570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1072 Acc: 0.9751\n",
      "Early stopping counter: 4\n",
      "Epoch 13/36\n",
      "----------\n",
      "Early Stopped since loss have not decreased for 4 epoch.\n",
      "Training complete in 1541m 55s\n",
      "Best val Acc: 0.975171\n"
     ]
    }
   ],
   "source": [
    "# fold 1 Best val Acc: 0.974806\n",
    "# fold 2 Best val Acc: 0.975171 \n",
    "model_ft, best_epoch = train_model(model_ft, dataloaders, criterion, optimizer, scheduler,0, NUM_EPOCH, DEVICE, PATIAENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log = pd.read_csv(f'{LOG_DIR}/log_{MODEL_NAME}_{VER}.csv')\n",
    "sns.lineplot(x=log['Epoch'], y=log['Valid Loss'], color='blue')\n",
    "sns.lineplot(x=log['Epoch'], y=log['Train Loss'], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model --- Stage 2\n",
    "\n",
    "model_ft = model_ft.to(DEVICE)\n",
    "\n",
    "save_path = f'{MDL_DIR}/{MODEL_NAME}_{VER}/{MODEL_NAME}_'+str(best_epoch)+'.pth'\n",
    "load_weights = torch.load(save_path)\n",
    "model_ft.load_state_dict(load_weights)\n",
    "\n",
    "#criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_ft.parameters(), lr=0.0001)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.7, patience=2, min_lr=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ef0edbd5414df08f7ed2eb05e44f37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0225 Acc: 0.9931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93ad207ca9bd4bbdbf1f363c4d5c5382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.0832 Acc: 0.9810\n",
      "Epoch 8/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183be52c9973474796a82ea8fe2269dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0136 Acc: 0.9960\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498bd4e9dfc44907aa3970677e315b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.0884 Acc: 0.9810\n",
      "Early stopping counter: 1\n",
      "Epoch 9/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c606251e90964e9d92a9032ba8470c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0095 Acc: 0.9971\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1595929bb5f74e4dbf5178f35f1bdb2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.0958 Acc: 0.9809\n",
      "Early stopping counter: 2\n",
      "Epoch 10/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30add1d5a514c5eb2793dfe92d407d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0069 Acc: 0.9979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8820370b9a87481b9b69d9142db4d4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.0997 Acc: 0.9811\n",
      "Early stopping counter: 3\n",
      "Epoch 11/36\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f6f7e2ddd740ad8e64d8d5a32b1841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5649.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train Loss: 0.0046 Acc: 0.9987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e88722942341b9a0525b63f8c18bd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "val Loss: 0.1055 Acc: 0.9813\n",
      "Early stopping counter: 4\n",
      "Epoch 12/36\n",
      "----------\n",
      "Early Stopped since loss have not decreased for 4 epoch.\n",
      "Training complete in 641m 14s\n",
      "Best val Acc: 0.981328\n"
     ]
    }
   ],
   "source": [
    "model_ft, best_epoch = train_model(model_ft, dataloaders, criterion, optimizer, scheduler,6, NUM_EPOCH, DEVICE, PATIAENCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_recall(pred_labels, y, n_grapheme=168, n_vowel=11, n_consonant=7):\n",
    "    recall_grapheme = sklearn.metrics.recall_score(pred_labels[0], y[0], average='macro')\n",
    "    recall_vowel = sklearn.metrics.recall_score(pred_labels[1], y[1], average='macro')\n",
    "    recall_consonant = sklearn.metrics.recall_score(pred_labels[2], y[2], average='macro')\n",
    "    scores = [recall_grapheme, recall_vowel, recall_consonant]\n",
    "    final_score = np.average(scores, weights=[2, 1, 1])\n",
    "    print(f'recall: grapheme {recall_grapheme}, vowel {recall_vowel}, consonant {recall_consonant}, '\n",
    "           f'total {final_score}')\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, dataloaders, phase, device):\n",
    "    model.eval()\n",
    "    output_list = []\n",
    "    label_list = []\n",
    "    with torch.no_grad():\n",
    "        if phase == 'test':\n",
    "            for i, inputs in enumerate(tqdm(dataloaders)):\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, pred0 = torch.max(outputs[0], 1)\n",
    "                _, pred1 = torch.max(outputs[1], 1)\n",
    "                _, pred2 = torch.max(outputs[2], 1)\n",
    "                preds = (pred0, pred1, pred2)\n",
    "                output_list.append(preds)\n",
    "            return output_list\n",
    "        elif phase == 'val':\n",
    "            for i, (inputs, labels) in enumerate(tqdm(dataloaders)):\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, pred0 = torch.max(outputs[0], 1)\n",
    "                _, pred1 = torch.max(outputs[1], 1)\n",
    "                _, pred2 = torch.max(outputs[2], 1)\n",
    "                preds = (pred0, pred1, pred2)\n",
    "                output_list.append(preds)\n",
    "                label_list.append(labels.transpose(1,0))\n",
    "            return output_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path = f'{MDL_DIR}/{MODEL_NAME}_{VER}/{MODEL_NAME}_'+str(best_epoch)+'.pth'\n",
    "load_weights = torch.load(save_path)\n",
    "model_ft.load_state_dict(load_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_dataset 20084\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfacd223185a49478e6230c1c0afbd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=628.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Prediction ---\n",
    "data_type = 'val'\n",
    "valid_preds_list = []\n",
    "print('valid_dataset', len(valid_dataset))\n",
    "valid_preds_list, valid_label_list = predict(model_ft, valid_loader, data_type, DEVICE)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0 (20084,) p1 (20084,) p2 (20084,)\n",
      "a0 (20084,) a1 (20084,) a2 (20084,)\n",
      "recall: grapheme 0.9645096549282974, vowel 0.9897832940731021, consonant 0.978486382031568, total 0.9743222464903162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9743222464903162"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each test_preds indicates the prediction outputs of different batch\n",
    "p0 = np.concatenate([valid_preds[0].cpu().numpy() for valid_preds in valid_preds_list], axis=0)\n",
    "p1 = np.concatenate([valid_preds[1].cpu().numpy() for valid_preds in valid_preds_list], axis=0)\n",
    "p2 = np.concatenate([valid_preds[2].cpu().numpy() for valid_preds in valid_preds_list], axis=0)\n",
    "print('p0', p0.shape, 'p1', p1.shape, 'p2', p2.shape)\n",
    "\n",
    "a0 = np.concatenate([valid_label[0].cpu().numpy() for valid_label in valid_label_list], axis=0)\n",
    "a1 = np.concatenate([valid_label[1].cpu().numpy() for valid_label in valid_label_list], axis=0)\n",
    "a2 = np.concatenate([valid_label[2].cpu().numpy() for valid_label in valid_label_list], axis=0)\n",
    "print('a0', a0.shape, 'a1', a1.shape, 'a2', a2.shape)\n",
    "\n",
    "pred_labels = [p0, p1, p2]\n",
    "y = [a0, a1, a2]\n",
    "macro_recall(pred_labels, y, n_grapheme=168, n_vowel=11, n_consonant=7)\n",
    "#fold 1 Stage-1 CV :0.9659313780016296 --> Stage-2 0.9666139805270331\n",
    "#fold 2 Stage-1 CV :0.9698549400969805 --> Stage 2 0.9743222464903162"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prediction ---\n",
    "data_type = 'test'\n",
    "test_preds_list = []\n",
    "for i in range(4):\n",
    "    # --- prepare data ---\n",
    "    indices = [i]\n",
    "    test_images = prepare_image(\n",
    "        DATADIR, FEATHERDIR, data_type = data_type, submission=True, indices=indices)\n",
    "    n_dataset = len(test_images)\n",
    "    print(f'i={i}, n_dataset={n_dataset}')\n",
    "    # test_data_size = 200 if debug else int(n_dataset * 0.9)\n",
    "    test_dataset = BengaliAIDataset(\n",
    "    test_images, None,\n",
    "    transform=data_transforms[data_type])\n",
    "    print('test_dataset', len(test_dataset))\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=WORKER)\n",
    "    \n",
    "    test_preds_list = predict(model_ft, test_loader, data_type,DEVICE)\n",
    "    del test_images\n",
    "    gc.collect()\n",
    "    if DEBUG:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each test_preds indicates the prediction outputs of different batch\n",
    "p0 = np.concatenate([test_preds[0].cpu().numpy() for test_preds in test_preds_list], axis=0)\n",
    "p1 = np.concatenate([test_preds[1].cpu().numpy() for test_preds in test_preds_list], axis=0)\n",
    "p2 = np.concatenate([test_preds[2].cpu().numpy() for test_preds in test_preds_list], axis=0)\n",
    "print('p0', p0.shape, 'p1', p1.shape, 'p2', p2.shape)\n",
    "\n",
    "row_id = []\n",
    "target = []\n",
    "for i in tqdm(range(len(p0))):\n",
    "    row_id += [f'Test_{i}_grapheme_root', f'Test_{i}_vowel_diacritic',\n",
    "               f'Test_{i}_consonant_diacritic']\n",
    "    target += [p0[i], p1[i], p2[i]]\n",
    "pred_df = pd.DataFrame({'row_id': row_id, 'target': target})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
